{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Naive CNN Identifier\n",
    "_A Naive CNN Application to AI Generated Image Detection_\n",
    "\n",
    "Wesley Jones - Digital Forensics, CprE 536 - Iowa State University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Background\n",
    "\n",
    "Convolutional neural networks (CNN) are a method of deep learning that will allow you to build an AI.\n",
    "\n",
    "The advantge of using a CNN for AI image related tasks is the natural ability of the model to identify parameters _unsupervised_.\n",
    "\n",
    "<img src=\"images/2D_Convolution_Animation.gif\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "* _image source_: <https://en.wikipedia.org/wiki/Convolution#Discrete_convolution>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Naive Approach and Related Works\n",
    "\n",
    "I'm not the first one to think of this. Common implementations:\n",
    "\n",
    "* Focus on identifying specfic parameters or artifacts about images\n",
    "* Rely on less quality testing data sets\n",
    "* Naive approaches perform at chance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objective and Motiviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Objective\n",
    "\n",
    "My objective is to implement a naive CNN model that can identify a human face as real or snythetically generated. It is to be training on high quality images and should have real world replication -- in that it can identify images that would be passed off as real people in real world settings.\n",
    "\n",
    "* A naive approach indicates that image pre-processing, custom parameterization, and model filtering/domain training is **not** utilized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Motivation\n",
    "\n",
    "The increased _sharing_ of AI generated materials and increased _development_ of high quality content generated with AI models means digital forensics will need the lowest overhead possible for quick and reliable identification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Methodology\n",
    "\n",
    "1. Acquire datasets for training\n",
    "2. Run and save the model\n",
    "3. Develop a testing dataset\n",
    "4. Gather predictions of testing dataset from the saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training\n",
    "\n",
    "* I used 160,000 images to train the model on two parameters, \"real\" and \"synth\". The model was trained in 15 epochs, with training dataset validation reaching >95% at epoch 10 and 99% by epoch 15.\n",
    "* Training occured with Python TensorFlow, using an HPC and nVidia A100s. The total training took just under 14.5 hours.\n",
    "* TensorFlow uses a modelling software called keras. This allowed me to save and reload the model to quickly make perdictions against.\n",
    "\n",
    "| Purpose | Image Count | Classes |\n",
    "| --- | --- | --- |\n",
    "| Training | 112,952 | 2 |\n",
    "| Test | 16,136 | 2 |\n",
    "| Validation | 32,273 | 2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generating Test Data\n",
    "\n",
    "I used the following prompt in current AI image generators to generate images I would ask my naive CNN model to predict.\n",
    "\n",
    "```plain\n",
    "{race} {gender} looking directly at the camera for a professional headshot taken using a Sony A7 III camera with 1/250, f/1.4, ISO 200 - FE 35mm 1.4 ZA - Portrait Style and 6200 K\n",
    "```\n",
    "\n",
    "**Generating models used**\n",
    "* Turbo SDXL\n",
    "* Fast SDXL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Issues with generated data\n",
    "\n",
    "* Models are reluctant to supply women presenting faces unless specifically prompted.\n",
    "* Cultural issues with specific prompts:\n",
    "\n",
    "```plain\n",
    "Native American {gender} looking directly at the camera for a professional headshot taken using a Sony A7 III camera with 1/250, f/1.4, ISO 200 - FE 35mm 1.4 ZA - Portrait Style and 6200 K\n",
    "```\n",
    "\n",
    "<img src=\"images/na_woman.jpg\" alt=\"Native American woman\" width=\"120\"/>\n",
    "<img src=\"images/na_person_3.jpg\" alt=\"Native American woman\" width=\"120\"/>\n",
    "\n",
    "\n",
    "* Due to the nature of these generative models the faces had _a lot_ of similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "* Model performed at chance across the board (~50%)\n",
    "* Turbo SDXL was noticiably _wrong_; Fast SDXL was noticably _correct_\n",
    "* (not) Shocking contribution: there's an issue with pre-processing, sizing, or tensor correlation.\n",
    "\n",
    "_All of the images tested were synthetic._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Test prediction results overview. Notice the similarities in the exact prediction results. If the model determines an image is real or synthetic it is very confident in this result.\n",
    "\n",
    "* _1 = synthetic_\n",
    "* _2 = real_\n",
    "\n",
    "![](images/selected.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Selected results focused on the middling predictions. Anything falling below 0.5 is considered a real image by the prediction.\n",
    "\n",
    "![](images/zoom_selected.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This plot highlights the performance of each model. This is not an incremental model - the x-axis indicates the index number of an image, a counter that increases as subsequent images are tested. The x-axis indicates the dividing line. Prediction values < 0.5 are determined to be real. A perfect test would result in all predictions being > 0.5\n",
    "\n",
    "![](images/selected_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dicussion & Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What went wrong?\n",
    "\n",
    "* Pre-processing for sizing and tensor alignment\n",
    "* Image quality didn't seem to play a factor in correct predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Future Work\n",
    "\n",
    "* Additional layers for CNNs to improve results\n",
    "* Changing the scope of parameters to fix confidence in incorrect results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "* Meta announces AI face generator this week, <imagine.meta.com>\n",
    "* Paper pre-release December 7, 2023 â€“ MonoGaussianAvatar: Monocular Gaussian Point-based Head Avatar\n",
    "    * https://yufan1012.github.io/MonoGaussianAvatar\n",
    "\n",
    "<img src=\"images/imagine_meta.png\" alt=\"Meta image generated with faces\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Resources\n",
    "\n",
    "* See my codebase for details: <https://github.com/iamwpj/naive-cnn-identifier>\n",
    "\n",
    "![](images/qr-iamwpj-github.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
